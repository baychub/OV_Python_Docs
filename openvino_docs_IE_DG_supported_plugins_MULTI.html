
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Multi-Device Plugin &#8212; OpenVINO Toolkit  documentation</title>
    
  <link href="_static/css/theme.css" rel="stylesheet" />
  <link href="_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/basic.css" />
    <link rel="stylesheet" type="text/css" href="_static/css/spark_sphinx_theme.css" />
    <link rel="stylesheet" type="text/css" href="_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/css/custom.css" />
    <link rel="stylesheet" type="text/css" href="_static/css/spark_sphinx_theme.css" />
    <link rel="stylesheet" type="text/css" href="_static/doxyrest-pygments.css" />
    
  <link rel="preload" as="script" href="_static/js/index.1c5a1a01449ed65a7b51.js">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/tabs.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/js/custom.js"></script>
    <script src="_static/target-highlight.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    

<a class="navbar-brand" href="index.html">
  <img src="logo.svg" class="logo" alt="logo">
</a>


    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="get_started.html">
  Get Started
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="documentation.html">
  Documentation
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="tutorials.html">
  Tutorials
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="group_api_ref.html">
  API Reference
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/ntyukaev/openvino" rel="noopener" target="_blank" title="GitHub">
            <span><i class="fab fa-github-square"></i></span>
            <label class="sr-only">GitHub</label>
          </a>
        </li>
      </ul>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    


<div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
  
    <div class="card-body docutils version-selector">
      <details class="sphinx-bs dropdown card mb-3">
        <summary class="summary-title card-header">
          <span class="fa mr-1"></span>
          Versions ( latest )
        </summary>
        <div class="summary-content card-body docutils">
          
          <dd><a href="/en/latest//openvino_docs_IE_DG_supported_plugins_MULTI.html">latest</a></dd>
          
          <dd><a href="/en/2022.1//openvino_docs_IE_DG_supported_plugins_MULTI.html">2022.1</a></dd>
          
        </div>
      </details>
    </div>
  
  
    <div class="card-body docutils language-selector">
      <details class="sphinx-bs dropdown card mb-3">
        <summary class="summary-title card-header">
          <span class="fa mr-1"></span>
          Languages ( en )
        </summary>
        <div class="summary-content card-body docutils">
          
          <dd><a href="/en/latest//openvino_docs_IE_DG_supported_plugins_MULTI.html">English</a></dd>
          
          <dd><a href="/cn/latest//openvino_docs_IE_DG_supported_plugins_MULTI.html">Chinese</a></dd>
          
        </div>
      </details>
    </div>
  
</div>



    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    
  </div>
</nav>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
              
              <div class="toc-item">
                
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#introducing-the-multi-device-plugin">
   Introducing the Multi-Device Plugin
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#defining-and-configuring-the-multi-device-plugin">
   Defining and Configuring the Multi-Device plugin
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#enumerating-available-devices">
   Enumerating Available Devices
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#configuring-the-individual-devices-and-creating-the-multi-device-on-top">
   Configuring the Individual Devices and Creating the Multi-Device On Top
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#querying-the-optimal-number-of-inference-requests">
   Querying the Optimal Number of Inference Requests
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#using-the-multi-device-with-openvino-samples-and-benchmarking-the-performance">
   Using the Multi-Device with OpenVINO Samples and Benchmarking the Performance
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#video-multi-plugin">
   Video: MULTI Plugin
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#see-also">
   See Also
  </a>
 </li>
</ul>

</nav>
              </div>
              
              <div class="toc-item">
                

<div class="tocsection editthispage">
    <a href="https://github.com/ntyukaev/openvino/edit/feature/ntyukaev/to-sphinx/docs/IE_DG/supported_plugins/MULTI.md">
        <i class="fas fa-pencil-alt"></i> Edit page
    </a>
</div>

              </div>
              
            
          </div>
          

          
    
        
    
    <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
      
          <div>
            
  <div class="section" id="multi-device-plugin">
<span id="doxid-openvino-docs-i-e-d-g-supported-plugins-m-u-l-t-i"></span><span id="index-0"></span><h1>Multi-Device Plugin<a class="headerlink" href="#multi-device-plugin" title="Permalink to this headline">¶</a></h1>
<p><span class="target" id="doxid-openvino-docs-i-e-d-g-supported-plugins-m-u-l-t-i-1md-openvino-docs-ie-dg-supported-plugins-multi"></span></p>
<div class="section" id="introducing-the-multi-device-plugin">
<h2>Introducing the Multi-Device Plugin<a class="headerlink" href="#introducing-the-multi-device-plugin" title="Permalink to this headline">¶</a></h2>
<p>The Multi-Device plugin automatically assigns inference requests to available computational devices to execute the requests in parallel. Potential gains are as follows:</p>
<ul class="simple">
<li><p>Improved throughput that multiple devices can deliver (compared to single-device execution)</p></li>
<li><p>More consistent performance, since the devices can now share the inference burden (so that if one device is becoming too busy, another device can take more of the load)</p></li>
</ul>
<p>Notice that with multi-device the application logic is left unchanged, so you don’t need to explicitly load the network to every device, create and balance the inference requests and so on. From the application point of view, this is just another device that handles the actual machinery. The only thing that is required to leverage performance is to provide the multi-device (and hence the underlying devices) with enough inference requests to crunch. For example, if you were processing 4 cameras on the CPU (with 4 inference requests), you may now want to process more cameras (with more requests in flight) to keep CPU+GPU busy via multi-device.</p>
<p>The “setup” of Multi-Device can be described in three major steps:</p>
<ul class="simple">
<li><p>First is configuration of each device as usual (e.g. via conventional SetConfig method)</p></li>
<li><p>Second is loading of a network to the Multi-Device plugin created on top of (prioritized) list of the configured devices. This is the only change that you need in your application.</p></li>
<li><p>Finally, just like with any other ExecutableNetwork (resulted from LoadNetwork) you just create as many requests as needed to saturate the devices. These steps are covered below in details.</p></li>
</ul>
</div>
<div class="section" id="defining-and-configuring-the-multi-device-plugin">
<h2>Defining and Configuring the Multi-Device plugin<a class="headerlink" href="#defining-and-configuring-the-multi-device-plugin" title="Permalink to this headline">¶</a></h2>
<p>Following the OpenVINO notions of “devices”, the Multi-Device has a “MULTI” name. The only configuration option for the Multi-Device plugin is a prioritized list of devices to use:</p>
<table class="table">
<colgroup>
<col style="width: 25%" />
<col style="width: 42%" />
<col style="width: 7%" />
<col style="width: 26%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Parameter name</p></th>
<th class="head"><p>Parameter values</p></th>
<th class="head"><p>Default</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>“MULTI_DEVICE_PRIORITIES”</p></td>
<td><p>comma-separated device names with no spaces</p></td>
<td><p>N/A</p></td>
<td><p>Prioritized list of devices</p></td>
</tr>
</tbody>
</table>
<p>You can use name of the configuration directly as a string, or use <code class="docutils literal notranslate"><span class="pre">MultiDeviceConfigParams::KEY_MULTI_DEVICE_PRIORITIES</span> <span class="pre">from</span> <span class="pre">the</span> <span class="pre">multi/multi_device_config.hpp</span></code>, which defines the same string.</p>
<p>Basically, there are three ways to specify the devices to be use by the “MULTI”:</p>
<pre class="highlight literal-block"><span></span><span class="n">Core</span> <span class="n">ie</span><span class="p">;</span>
<span class="k">auto</span> <span class="n">network</span> <span class="o">=</span> <span class="n">ie</span><span class="p">.</span><span class="n">ReadNetwork</span><span class="p">(</span><span class="s">&quot;sample.xml&quot;</span><span class="p">);</span>
<span class="c1">//NEW IE-CENTRIC API, the &quot;MULTI&quot; plugin is (globally) pre-configured with the explicit option:</span>
<span class="n">ie</span><span class="p">.</span><span class="n">SetConfig</span><span class="p">({{</span><span class="s">&quot;MULTI_DEVICE_PRIORITIES&quot;</span><span class="p">,</span> <span class="s">&quot;HDDL,GPU&quot;</span><span class="p">}},</span> <span class="s">&quot;MULTI&quot;</span><span class="p">);</span>
<span class="n">ExecutableNetwork</span> <span class="n">exec0</span> <span class="o">=</span> <span class="n">ie</span><span class="p">.</span><span class="n">LoadNetwork</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="s">&quot;MULTI&quot;</span><span class="p">,</span> <span class="p">{});</span>

<span class="c1">//NEW IE-CENTRIC API, configuration of the &quot;MULTI&quot; is part of the network configuration (and hence specific to the network):</span>
<span class="n">ExecutableNetwork</span> <span class="n">exec1</span> <span class="o">=</span> <span class="n">ie</span><span class="p">.</span><span class="n">LoadNetwork</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="s">&quot;MULTI&quot;</span><span class="p">,</span> <span class="p">{{</span><span class="s">&quot;MULTI_DEVICE_PRIORITIES&quot;</span><span class="p">,</span> <span class="s">&quot;HDDL,GPU&quot;</span><span class="p">}});</span>
<span class="c1">//NEW IE-CENTRIC API, same as previous, but configuration of the &quot;MULTI&quot; is part of the name (so config is empty), also network-specific:</span>
<span class="n">ExecutableNetwork</span> <span class="n">exec2</span> <span class="o">=</span> <span class="n">ie</span><span class="p">.</span><span class="n">LoadNetwork</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="s">&quot;MULTI:HDDL,GPU&quot;</span><span class="p">,</span> <span class="p">{});</span></pre>
<p>Notice that the priorities of the devices can be changed in real time for the executable network:</p>
<pre class="highlight literal-block"><span></span><span class="n">Core</span> <span class="n">ie</span><span class="p">;</span>
<span class="k">auto</span> <span class="n">network</span> <span class="o">=</span> <span class="n">ie</span><span class="p">.</span><span class="n">ReadNetwork</span><span class="p">(</span><span class="s">&quot;sample.xml&quot;</span><span class="p">);</span>
<span class="n">ExecutableNetwork</span> <span class="n">exec</span> <span class="o">=</span> <span class="n">ie</span><span class="p">.</span><span class="n">LoadNetwork</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="s">&quot;MULTI:HDDL,GPU&quot;</span><span class="p">,</span> <span class="p">{});</span>
<span class="c1">//...</span>
<span class="n">exec</span><span class="p">.</span><span class="n">SetConfig</span><span class="p">({{</span><span class="s">&quot;MULTI_DEVICE_PRIORITIES&quot;</span><span class="p">,</span> <span class="s">&quot;GPU,HDDL&quot;</span><span class="p">}});</span>
<span class="c1">// you can even exclude some device</span>
<span class="n">exec</span><span class="p">.</span><span class="n">SetConfig</span><span class="p">({{</span><span class="s">&quot;MULTI_DEVICE_PRIORITIES&quot;</span><span class="p">,</span> <span class="s">&quot;GPU&quot;</span><span class="p">}});</span>
<span class="c1">//...</span>
<span class="c1">// and then return it back</span>
<span class="n">exec</span><span class="p">.</span><span class="n">SetConfig</span><span class="p">({{</span><span class="s">&quot;MULTI_DEVICE_PRIORITIES&quot;</span><span class="p">,</span> <span class="s">&quot;GPU,HDDL&quot;</span><span class="p">}});</span>
<span class="c1">//but you cannot add new devices on the fly, the next line will trigger the following exception:</span>
<span class="c1">//[ ERROR ] [NOT_FOUND] You can only change device priorities but not add new devices with the Network&#39;s SetConfig(MultiDeviceConfigParams::KEY_MULTI_DEVICE_PRIORITIES.</span>
<span class="c1">//CPU device was not in the original device list!</span>
<span class="n">exec</span><span class="p">.</span><span class="n">SetConfig</span><span class="p">({{</span><span class="s">&quot;MULTI_DEVICE_PRIORITIES&quot;</span><span class="p">,</span> <span class="s">&quot;CPU,GPU,HDDL&quot;</span><span class="p">}});</span></pre>
<p>Finally, there is a way to specify number of requests that the multi-device will internally keep for each device. Suppose your original app was running 4 cameras with 4 inference requests. You would probably want to share these 4 requests between 2 devices used in the MULTI. The easiest way is to specify a number of requests for each device using parentheses: “MULTI:CPU(2),GPU(2)” and use the same 4 requests in your app. However, such an explicit configuration is not performance-portable and hence not recommended. Instead, the better way is to configure the individual devices and query the resulting number of requests to be used at the application level (see <a class="reference external" href="#configuring-the-individual-devices-and-creating-the-multi-device-on-top">Configuring the Individual Devices and Creating the Multi-Device On Top</a>).</p>
</div>
<div class="section" id="enumerating-available-devices">
<h2>Enumerating Available Devices<a class="headerlink" href="#enumerating-available-devices" title="Permalink to this headline">¶</a></h2>
<p>Inference Engine now features a dedicated API to enumerate devices and their capabilities. See <a class="reference internal" href="openvino_inference_engine_samples_hello_query_device_README.html#doxid-openvino-inference-engine-samples-hello-query-device-r-e-a-d-m-e"><span class="std std-ref">Hello Query Device C++ Sample</span></a>. This is example output from the sample (truncated to the devices’ names only):</p>
<pre class="highlight literal-block"><span></span><span class="p">.</span><span class="o">/</span><span class="n">hello_query_device</span>
<span class="n">Available</span> <span class="nl">devices</span><span class="p">:</span>
    <span class="nl">Device</span><span class="p">:</span> <span class="n">CPU</span>
<span class="p">...</span>
    <span class="nl">Device</span><span class="p">:</span> <span class="n">GPU</span><span class="mf">.0</span>
<span class="p">...</span>
    <span class="nl">Device</span><span class="p">:</span> <span class="n">GPU</span><span class="mf">.1</span>
<span class="p">...</span>
    <span class="nl">Device</span><span class="p">:</span> <span class="n">HDDL</span></pre>
<p>A simple programmatic way to enumerate the devices and use with the multi-device is as follows:</p>
<pre class="highlight literal-block"><span></span><span class="n">Core</span> <span class="n">ie</span><span class="p">;</span>
<span class="k">auto</span> <span class="n">cnnNetwork</span> <span class="o">=</span> <span class="n">ie</span><span class="p">.</span><span class="n">ReadNetwork</span><span class="p">(</span><span class="s">&quot;sample.xml&quot;</span><span class="p">);</span>
<span class="n">std</span><span class="o">::</span><span class="n">string</span> <span class="n">allDevices</span> <span class="o">=</span> <span class="s">&quot;MULTI:&quot;</span><span class="p">;</span>
<span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="o">&gt;</span> <span class="n">availableDevices</span> <span class="o">=</span> <span class="n">ie</span><span class="p">.</span><span class="n">GetAvailableDevices</span><span class="p">();</span>
<span class="k">for</span> <span class="p">(</span><span class="k">auto</span> <span class="o">&amp;&amp;</span> <span class="nl">device</span> <span class="p">:</span> <span class="n">availableDevices</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">allDevices</span> <span class="o">+=</span> <span class="n">device</span><span class="p">;</span>
    <span class="n">allDevices</span> <span class="o">+=</span> <span class="p">((</span><span class="n">device</span> <span class="o">==</span> <span class="n">availableDevices</span><span class="p">[</span><span class="n">availableDevices</span><span class="p">.</span><span class="n">size</span><span class="p">()</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span> <span class="o">?</span> <span class="s">&quot;&quot;</span> <span class="o">:</span> <span class="s">&quot;,&quot;</span><span class="p">);</span>
<span class="p">}</span>
<span class="n">ExecutableNetwork</span> <span class="n">exeNetwork</span> <span class="o">=</span> <span class="n">ie</span><span class="p">.</span><span class="n">LoadNetwork</span><span class="p">(</span><span class="n">cnnNetwork</span><span class="p">,</span> <span class="n">allDevices</span><span class="p">,</span> <span class="p">{});</span></pre>
<p>Beyond the trivial “CPU”, “GPU”, “HDDL” and so on, when multiple instances of a device are available the names are more qualified. For example, this is how two Intel® Movidius™ Myriad™ X sticks are listed with the hello_query_sample:</p>
<pre class="highlight literal-block"><span></span><span class="p">...</span>
    <span class="nl">Device</span><span class="p">:</span> <span class="n">MYRIAD</span><span class="mf">.1.2</span><span class="o">-</span><span class="n">ma2480</span>
<span class="p">...</span>
    <span class="nl">Device</span><span class="p">:</span> <span class="n">MYRIAD</span><span class="mf">.1.4</span><span class="o">-</span><span class="n">ma2480</span></pre>
<p>So the explicit configuration to use both would be “MULTI:MYRIAD.1.2-ma2480,MYRIAD.1.4-ma2480”. Accordingly, the code that loops over all available devices of “MYRIAD” type only is below:</p>
<pre class="highlight literal-block"><a class="reference internal" href="class_InferenceEngine_Core.html#doxid-class-inference-engine-1-1-core"><span class="std std-ref">InferenceEngine::Core</span></a><span></span> <span class="n">ie</span><span class="p">;</span>
<span class="k">auto</span> <span class="n">cnnNetwork</span> <span class="o">=</span> <span class="n">ie</span><span class="p">.</span><a class="reference internal" href="class_InferenceEngine_Core.html#doxid-class-inference-engine-1-1-core-1ac716dda382aefd09264b60ea40def3ef"><span class="std std-ref">ReadNetwork</span></a><span></span><span class="p">(</span><span class="s">&quot;sample.xml&quot;</span><span class="p">);</span>
<span class="n">std</span><span class="o">::</span><span class="n">string</span> <span class="n">allDevices</span> <span class="o">=</span> <span class="s">&quot;MULTI:&quot;</span><span class="p">;</span>
<span class="n">std</span><span class="o">::</span><span class="n">vector</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="o">&gt;</span> <span class="n">myriadDevices</span> <span class="o">=</span> <span class="n">ie</span><span class="p">.</span><a class="reference internal" href="class_InferenceEngine_Core.html#doxid-class-inference-engine-1-1-core-1ada42cbc50479ccab13bd16d3c6eba885"><span class="std std-ref">GetMetric</span></a><span></span><span class="p">(</span><span class="s">&quot;MYRIAD&quot;</span><span class="p">,</span> <a class="reference internal" href="global.html#doxid-ie-plugin-config-8hpp-1a69d0efa20c5b2bec020a706279f0c7be"><span class="std std-ref">METRIC_KEY</span></a><span></span><span class="p">(</span><span class="n">AVAILABLE_DEVICES</span><span class="p">));</span>
<span class="k">for</span> <span class="p">(</span><span class="kt">size_t</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">myriadDevices</span><span class="p">.</span><span class="n">size</span><span class="p">();</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">allDevices</span> <span class="o">+=</span> <span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="p">(</span><span class="s">&quot;MYRIAD.&quot;</span><span class="p">)</span>
                            <span class="o">+</span> <span class="n">myriadDevices</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                            <span class="o">+</span> <span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="p">(</span><span class="n">i</span> <span class="o">&lt;</span> <span class="p">(</span><span class="n">myriadDevices</span><span class="p">.</span><span class="n">size</span><span class="p">()</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">?</span> <span class="s">&quot;,&quot;</span> <span class="o">:</span> <span class="s">&quot;&quot;</span><span class="p">);</span>
<span class="p">}</span>
<a class="reference internal" href="class_InferenceEngine_ExecutableNetwork.html#doxid-class-inference-engine-1-1-executable-network"><span class="std std-ref">InferenceEngine::ExecutableNetwork</span></a><span></span> <span class="n">exeNetwork</span> <span class="o">=</span> <span class="n">ie</span><span class="p">.</span><a class="reference internal" href="class_InferenceEngine_Core.html#doxid-class-inference-engine-1-1-core-1a7ac4bd8bc351fae833aaa0db84fab738"><span class="std std-ref">LoadNetwork</span></a><span></span><span class="p">(</span><span class="n">cnnNetwork</span><span class="p">,</span> <span class="n">allDevices</span><span class="p">,</span> <span class="p">{});</span></pre>
</div>
<div class="section" id="configuring-the-individual-devices-and-creating-the-multi-device-on-top">
<h2>Configuring the Individual Devices and Creating the Multi-Device On Top<a class="headerlink" href="#configuring-the-individual-devices-and-creating-the-multi-device-on-top" title="Permalink to this headline">¶</a></h2>
<p>As discussed in the first section, you shall configure each individual device as usual and then just create the “MULTI” device on top:</p>
<pre class="highlight literal-block"><span></span><span class="c1">// configure the HDDL device first</span>
<a class="reference internal" href="class_InferenceEngine_Core.html#doxid-class-inference-engine-1-1-core"><span class="std std-ref">InferenceEngine::Core</span></a><span></span> <span class="n">ie</span><span class="p">;</span>
<a class="reference internal" href="class_InferenceEngine_CNNNetwork.html#doxid-class-inference-engine-1-1-c-n-n-network"><span class="std std-ref">InferenceEngine::CNNNetwork</span></a><span></span> <span class="n">cnnNetwork</span> <span class="o">=</span> <span class="n">ie</span><span class="p">.</span><a class="reference internal" href="class_InferenceEngine_Core.html#doxid-class-inference-engine-1-1-core-1ac716dda382aefd09264b60ea40def3ef"><span class="std std-ref">ReadNetwork</span></a><span></span><span class="p">(</span><span class="s">&quot;sample.xml&quot;</span><span class="p">);</span>
<span class="n">ie</span><span class="p">.</span><a class="reference internal" href="class_InferenceEngine_Core.html#doxid-class-inference-engine-1-1-core-1a34aa9ac6fb237b634d5bf08b288e88d4"><span class="std std-ref">SetConfig</span></a><span></span><span class="p">(</span><span class="n">hddl_config</span><span class="p">,</span> <span class="s">&quot;HDDL&quot;</span><span class="p">);</span>
<span class="c1">// configure the GPU device</span>
<span class="n">ie</span><span class="p">.</span><a class="reference internal" href="class_InferenceEngine_Core.html#doxid-class-inference-engine-1-1-core-1a34aa9ac6fb237b634d5bf08b288e88d4"><span class="std std-ref">SetConfig</span></a><span></span><span class="p">(</span><span class="n">gpu_config</span><span class="p">,</span> <span class="s">&quot;GPU&quot;</span><span class="p">);</span>
<span class="c1">// load the network to the multi-device, while specifying the configuration (devices along with priorities):</span>
<a class="reference internal" href="class_InferenceEngine_ExecutableNetwork.html#doxid-class-inference-engine-1-1-executable-network"><span class="std std-ref">InferenceEngine::ExecutableNetwork</span></a><span></span> <span class="n">exeNetwork</span> <span class="o">=</span> <span class="n">ie</span><span class="p">.</span><a class="reference internal" href="class_InferenceEngine_Core.html#doxid-class-inference-engine-1-1-core-1a7ac4bd8bc351fae833aaa0db84fab738"><span class="std std-ref">LoadNetwork</span></a><span></span><span class="p">(</span><span class="n">cnnNetwork</span><span class="p">,</span> <span class="s">&quot;MULTI&quot;</span><span class="p">,</span> <span class="p">{{</span><span class="n">InferenceEngine</span><span class="o">::</span><span class="n">MultiDeviceConfigParams</span><span class="o">::</span><span class="n">KEY_MULTI_DEVICE_PRIORITIES</span><span class="p">,</span> <span class="s">&quot;HDDL,GPU&quot;</span><span class="p">}});</span>
<span class="c1">// new metric allows to query the optimal number of requests:</span>
<span class="kt">uint32_t</span> <span class="n">nireq</span> <span class="o">=</span> <span class="n">exeNetwork</span><span class="p">.</span><a class="reference internal" href="class_InferenceEngine_ExecutableNetwork.html#doxid-class-inference-engine-1-1-executable-network-1a5b38590cad3a68144c679af5f5a6090d"><span class="std std-ref">GetMetric</span></a><span></span><span class="p">(</span><a class="reference internal" href="global.html#doxid-ie-plugin-config-8hpp-1a69d0efa20c5b2bec020a706279f0c7be"><span class="std std-ref">METRIC_KEY</span></a><span></span><span class="p">(</span><span class="n">OPTIMAL_NUMBER_OF_INFER_REQUESTS</span><span class="p">)).</span><a class="reference internal" href="class_InferenceEngine_Parameter.html#doxid-class-inference-engine-1-1-parameter-1aff35750d73d32578006a7f1ea753d6f1"><span class="std std-ref">as</span></a><span></span><span class="o">&lt;</span><span class="kt">unsigned</span> <span class="kt">int</span><span class="o">&gt;</span><span class="p">();</span></pre>
<p>Alternatively, you can combine all the individual device settings into single config and load that, allowing the Multi-Device plugin to parse and apply that to the right devices. See code example in the next section.</p>
<p>Notice that while the performance of accelerators combines really well with multi-device, the CPU+GPU execution poses some performance caveats, as these devices share the power, bandwidth and other resources. For example it is recommended to enable the GPU throttling hint (which save another CPU thread for the CPU inference). See section of the <a class="reference external" href="#using-the-multi-device-with-openvino-samples-and-benchmarking-the-performance">Using the multi-device with OpenVINO samples and benchmarking the performance</a> below.</p>
</div>
<div class="section" id="querying-the-optimal-number-of-inference-requests">
<h2>Querying the Optimal Number of Inference Requests<a class="headerlink" href="#querying-the-optimal-number-of-inference-requests" title="Permalink to this headline">¶</a></h2>
<p>Notice that until R2 you had to calculate number of requests in your application for any device, e.g. you had to know that Intel® Vision Accelerator Design with Intel® Movidius™ VPUs required at least 32 inference requests to perform well. Now you can use the new GetMetric API to query the optimal number of requests. Similarly, when using the multi-device you don’t need to sum over included devices yourself, you can query metric directly:</p>
<pre class="highlight literal-block"><a class="reference internal" href="class_InferenceEngine_Core.html#doxid-class-inference-engine-1-1-core"><span class="std std-ref">InferenceEngine::Core</span></a><span></span> <span class="n">ie</span><span class="p">;</span>
<a class="reference internal" href="class_InferenceEngine_CNNNetwork.html#doxid-class-inference-engine-1-1-c-n-n-network"><span class="std std-ref">InferenceEngine::CNNNetwork</span></a><span></span> <span class="n">cnnNetwork</span> <span class="o">=</span> <span class="n">ie</span><span class="p">.</span><a class="reference internal" href="class_InferenceEngine_Core.html#doxid-class-inference-engine-1-1-core-1ac716dda382aefd09264b60ea40def3ef"><span class="std std-ref">ReadNetwork</span></a><span></span><span class="p">(</span><span class="s">&quot;sample.xml&quot;</span><span class="p">);</span>
<span class="c1">// &#39;device_name&#39; can be &quot;MULTI:HDDL,GPU&quot; to configure the multi-device to use HDDL and GPU</span>
<a class="reference internal" href="class_InferenceEngine_ExecutableNetwork.html#doxid-class-inference-engine-1-1-executable-network"><span class="std std-ref">InferenceEngine::ExecutableNetwork</span></a><span></span> <span class="n">exeNetwork</span> <span class="o">=</span> <span class="n">ie</span><span class="p">.</span><a class="reference internal" href="class_InferenceEngine_Core.html#doxid-class-inference-engine-1-1-core-1a7ac4bd8bc351fae833aaa0db84fab738"><span class="std std-ref">LoadNetwork</span></a><span></span><span class="p">(</span><span class="n">cnnNetwork</span><span class="p">,</span> <span class="n">device_name</span><span class="p">,</span> <span class="n">full_config</span><span class="p">);</span>
<span class="c1">// new metric allows to query the optimal number of requests:</span>
<span class="kt">uint32_t</span> <span class="n">nireq</span> <span class="o">=</span> <span class="n">exeNetwork</span><span class="p">.</span><a class="reference internal" href="class_InferenceEngine_ExecutableNetwork.html#doxid-class-inference-engine-1-1-executable-network-1a5b38590cad3a68144c679af5f5a6090d"><span class="std std-ref">GetMetric</span></a><span></span><span class="p">(</span><a class="reference internal" href="global.html#doxid-ie-plugin-config-8hpp-1a69d0efa20c5b2bec020a706279f0c7be"><span class="std std-ref">METRIC_KEY</span></a><span></span><span class="p">(</span><span class="n">OPTIMAL_NUMBER_OF_INFER_REQUESTS</span><span class="p">)).</span><a class="reference internal" href="class_InferenceEngine_Parameter.html#doxid-class-inference-engine-1-1-parameter-1aff35750d73d32578006a7f1ea753d6f1"><span class="std std-ref">as</span></a><span></span><span class="o">&lt;</span><span class="kt">unsigned</span> <span class="kt">int</span><span class="o">&gt;</span><span class="p">();</span></pre>
</div>
<div class="section" id="using-the-multi-device-with-openvino-samples-and-benchmarking-the-performance">
<h2>Using the Multi-Device with OpenVINO Samples and Benchmarking the Performance<a class="headerlink" href="#using-the-multi-device-with-openvino-samples-and-benchmarking-the-performance" title="Permalink to this headline">¶</a></h2>
<p>Notice that every OpenVINO sample that supports “-d” (which stands for “device”) command-line option transparently accepts the multi-device. The <a class="reference internal" href="openvino_inference_engine_samples_benchmark_app_README.html#doxid-openvino-inference-engine-samples-benchmark-app-r-e-a-d-m-e"><span class="std std-ref">Benchmark Application</span></a> is the best reference to the optimal usage of the multi-device. As discussed multiple times earlier, you don’t need to setup number of requests, CPU streams or threads as the application provides optimal out of the box performance. Below is example command-line to evaluate HDDL+GPU performance with that:</p>
<pre class="highlight literal-block"><span></span><span class="p">.</span><span class="o">/</span><span class="n">benchmark_app</span> <span class="err">–</span><span class="n">d</span> <span class="nl">MULTI</span><span class="p">:</span><span class="n">HDDL</span><span class="p">,</span><span class="n">GPU</span> <span class="err">–</span><span class="n">m</span> <span class="o">&lt;</span><span class="n">model</span><span class="o">&gt;</span> <span class="o">-</span><span class="n">i</span> <span class="o">&lt;</span><span class="n">input</span><span class="o">&gt;</span> <span class="o">-</span><span class="n">niter</span> <span class="mi">1000</span></pre>
<p>Notice that you can use the FP16 IR to work with multi-device (as CPU automatically upconverts it to the fp32) and rest of devices support it naturally. Also notice that no demos are (yet) fully optimized for the multi-device, by means of supporting the OPTIMAL_NUMBER_OF_INFER_REQUESTS metric, using the GPU streams/throttling, and so on.</p>
</div>
<div class="section" id="video-multi-plugin">
<h2>Video: MULTI Plugin<a class="headerlink" href="#video-multi-plugin" title="Permalink to this headline">¶</a></h2>
<dl class="simple">
<dt><a href="#id1"><span class="problematic" id="id2">`</span></a></dt><dd><p>&lt;<a class="reference external" href="https://www.youtube.com/watch?v=xbORYFEmrqU">https://www.youtube.com/watch?v=xbORYFEmrqU</a>&gt;`__ &lt;iframe width=”560” height=”315” src=”<a class="reference external" href="https://www.youtube.com/embed/xbORYFEmrqU">https://www.youtube.com/embed/xbORYFEmrqU</a>” frameborder=”0” allow=”accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture” allowfullscreen&gt;&lt;/iframe&gt;</p>
</dd>
</dl>
</div>
<div class="section" id="see-also">
<h2>See Also<a class="headerlink" href="#see-also" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p><a class="reference internal" href="openvino_docs_IE_DG_supported_plugins_Supported_Devices.html#doxid-openvino-docs-i-e-d-g-supported-plugins-supported-devices"><span class="std std-ref">Supported Devices</span></a></p></li>
</ul>
</div>
</div>


          </div>
      
      
          <div class='prev-next-bottom'>
            

          </div>
      
    </main>


      </div>
    </div>
  
  <script src="_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  <footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="copyright">
    &copy; Copyright 2021, Intel.<br/>
</p>
    </div>
    
    <div class="footer-item">
      <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 4.1.1.<br/>
</p>
    </div>
    
  </div>
</footer>
  </body>
</html>