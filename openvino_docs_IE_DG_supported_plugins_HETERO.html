
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Heterogeneous Plugin &#8212; OpenVINO Toolkit  documentation</title>
    
  <link href="_static/css/theme.css" rel="stylesheet" />
  <link href="_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/basic.css" />
    <link rel="stylesheet" type="text/css" href="_static/css/spark_sphinx_theme.css" />
    <link rel="stylesheet" type="text/css" href="_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/css/custom.css" />
    <link rel="stylesheet" type="text/css" href="_static/css/spark_sphinx_theme.css" />
    <link rel="stylesheet" type="text/css" href="_static/doxyrest-pygments.css" />
    
  <link rel="preload" as="script" href="_static/js/index.1c5a1a01449ed65a7b51.js">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/tabs.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/js/custom.js"></script>
    <script src="_static/target-highlight.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <nav class="navbar navbar-light navbar-expand-lg bg-light fixed-top bd-navbar" id="navbar-main"><div class="container-xl">

  <div id="navbar-start">
    
    

<a class="navbar-brand" href="index.html">
  <img src="logo.svg" class="logo" alt="logo">
</a>


    
  </div>

  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbar-collapsible" aria-controls="navbar-collapsible" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  
  <div id="navbar-collapsible" class="col-lg-9 collapse navbar-collapse">
    <div id="navbar-center" class="mr-auto">
      
      <div class="navbar-center-item">
        <ul id="navbar-main-elements" class="navbar-nav">
    <li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="get_started.html">
  Get Started
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="documentation.html">
  Documentation
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="tutorials.html">
  Tutorials
 </a>
</li>

<li class="toctree-l1 nav-item">
 <a class="reference internal nav-link" href="group_api_ref.html">
  API Reference
 </a>
</li>

    
</ul>
      </div>
      
    </div>

    <div id="navbar-end">
      
      <div class="navbar-end-item">
        <ul id="navbar-icon-links" class="navbar-nav" aria-label="Icon Links">
        <li class="nav-item">
          <a class="nav-link" href="https://github.com/ntyukaev/openvino" rel="noopener" target="_blank" title="GitHub">
            <span><i class="fab fa-github-square"></i></span>
            <label class="sr-only">GitHub</label>
          </a>
        </li>
      </ul>
      </div>
      
    </div>
  </div>
</div>
    </nav>
    


<div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
  
    <div class="card-body docutils version-selector">
      <details class="sphinx-bs dropdown card mb-3">
        <summary class="summary-title card-header">
          <span class="fa mr-1"></span>
          Versions ( latest )
        </summary>
        <div class="summary-content card-body docutils">
          
          <dd><a href="/en/latest//openvino_docs_IE_DG_supported_plugins_HETERO.html">latest</a></dd>
          
          <dd><a href="/en/2022.1//openvino_docs_IE_DG_supported_plugins_HETERO.html">2022.1</a></dd>
          
        </div>
      </details>
    </div>
  
  
    <div class="card-body docutils language-selector">
      <details class="sphinx-bs dropdown card mb-3">
        <summary class="summary-title card-header">
          <span class="fa mr-1"></span>
          Languages ( en )
        </summary>
        <div class="summary-content card-body docutils">
          
          <dd><a href="/en/latest//openvino_docs_IE_DG_supported_plugins_HETERO.html">English</a></dd>
          
          <dd><a href="/cn/latest//openvino_docs_IE_DG_supported_plugins_HETERO.html">Chinese</a></dd>
          
        </div>
      </details>
    </div>
  
</div>



    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar"><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    
  </div>
</nav>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
              
              <div class="toc-item">
                
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#introducing-the-heterogeneous-plugin">
   Introducing the Heterogeneous Plugin
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#annotation-of-layers-per-device-and-default-fallback-policy">
   Annotation of Layers per Device and Default Fallback Policy
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#details-of-splitting-network-and-execution">
   Details of Splitting Network and Execution
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#execution-precision">
   Execution Precision
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#analyzing-heterogeneous-execution">
   Analyzing Heterogeneous Execution
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#see-also">
   See Also
  </a>
 </li>
</ul>

</nav>
              </div>
              
              <div class="toc-item">
                

<div class="tocsection editthispage">
    <a href="https://github.com/ntyukaev/openvino/edit/feature/ntyukaev/to-sphinx/docs/IE_DG/supported_plugins/HETERO.md">
        <i class="fas fa-pencil-alt"></i> Edit page
    </a>
</div>

              </div>
              
            
          </div>
          

          
    
        
    
    <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
      
          <div>
            
  <div class="section" id="heterogeneous-plugin">
<span id="doxid-openvino-docs-i-e-d-g-supported-plugins-h-e-t-e-r-o"></span><span id="index-0"></span><h1>Heterogeneous Plugin<a class="headerlink" href="#heterogeneous-plugin" title="Permalink to this headline">¶</a></h1>
<p><span class="target" id="doxid-openvino-docs-i-e-d-g-supported-plugins-h-e-t-e-r-o-1md-openvino-docs-ie-dg-supported-plugins-hetero"></span></p>
<div class="section" id="introducing-the-heterogeneous-plugin">
<h2>Introducing the Heterogeneous Plugin<a class="headerlink" href="#introducing-the-heterogeneous-plugin" title="Permalink to this headline">¶</a></h2>
<p>The heterogeneous plugin enables computing for inference on one network on several devices. The purposes of executing networks in heterogeneous mode:</p>
<ul class="simple">
<li><p>Utilize the power of accelerators to calculate heaviest parts of the network and execute unsupported layers on fallback devices like the CPU</p></li>
<li><p>Utilize all available hardware more efficiently during one inference</p></li>
</ul>
<p>The execution through heterogeneous plugin can be divided to two independent steps:</p>
<ul class="simple">
<li><p>Setting of affinity to layers</p></li>
<li><p>Loading a network to the Heterogeneous plugin, splitting the network to parts, and executing them through the plugin</p></li>
</ul>
<p>These steps are decoupled. The setting of affinity can be done automatically using fallback policy or in manual mode.</p>
<p>The fallback automatic policy causes “greedy” behavior and assigns all layers that can be executed on certain device according to the priorities you specify (for example, <code class="docutils literal notranslate"><span class="pre">HETERO:GPU,CPU</span></code>). Automatic policy does not take into account plugin peculiarities such as the inability to infer some layers without other special layers placed before or after that layer. The plugin is responsible for solving such cases. If the device plugin does not support the subgraph topology constructed by the Hetero plugin, then you should set affinity manually.</p>
<p>Some of the topologies are not friendly to heterogeneous execution on some devices or cannot be executed in such mode at all. Examples of such networks are networks having activation layers which are not supported on primary device. If transmitting data from one part of a network to another part in heterogeneous mode takes more time than in normal mode, it may not make sense to execute them in heterogeneous mode. In this case, you can define heaviest part manually and set the affinity to avoid sending data back and forth many times during one inference.</p>
</div>
<div class="section" id="annotation-of-layers-per-device-and-default-fallback-policy">
<h2>Annotation of Layers per Device and Default Fallback Policy<a class="headerlink" href="#annotation-of-layers-per-device-and-default-fallback-policy" title="Permalink to this headline">¶</a></h2>
<p>Default fallback policy decides which layer goes to which device automatically according to the support in dedicated plugins (FPGA, GPU, CPU, MYRIAD).</p>
<p>Another way to annotate a network is to set affinity manually using <code class="docutils literal notranslate"><a class="reference internal" href="class_ngraph_Node.html#doxid-classngraph-1-1-node-1a4cac2a92b8b099d4145d45d3f26f599c"><span class="std std-ref"><span class="pre">ngraph::Node::get_rt_info</span></span></a></code> with key <code class="docutils literal notranslate"><span class="pre">&quot;affinity&quot;</span></code> :</p>
<pre class="highlight literal-block"><span></span><span class="k">for</span> <span class="p">(</span><span class="k">auto</span> <span class="o">&amp;&amp;</span> <span class="nl">op</span> <span class="p">:</span> <span class="n">function</span><span class="o">-&gt;</span><span class="n">get_ops</span><span class="p">())</span>
    <span class="n">op</span><span class="o">-&gt;</span><span class="n">get_rt_info</span><span class="p">()[</span><span class="s">&quot;affinity&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">std</span><span class="o">::</span><span class="n">make_shared</span><span class="o">&lt;</span><span class="n">ngraph</span><span class="o">::</span><span class="n">VariantWrapper</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="o">&gt;&gt;</span><span class="p">(</span><span class="s">&quot;CPU&quot;</span><span class="p">);</span></pre>
<p>The fallback policy does not work if even one layer has an initialized affinity. The sequence should be calling of automating affinity settings and then fix manually.</p>
<p><strong>NOTE</strong> : If you set affinity manually, be careful at the current moment Inference Engine plugins don’t support constant (<code class="docutils literal notranslate"><span class="pre">Constant</span></code> -&gt; <code class="docutils literal notranslate"><span class="pre">Result</span></code>) and empty (<code class="docutils literal notranslate"><span class="pre">Parameter</span></code> -&gt; <code class="docutils literal notranslate"><span class="pre">Result</span></code>) networks. Please avoid such subgraphs when you set affinity manually.</p>
<pre class="highlight literal-block"><a class="reference internal" href="class_InferenceEngine_Core.html#doxid-class-inference-engine-1-1-core"><span class="std std-ref">InferenceEngine::Core</span></a><span></span> <span class="n">core</span><span class="p">;</span>
<span class="k">auto</span> <span class="n">network</span> <span class="o">=</span> <span class="n">core</span><span class="p">.</span><a class="reference internal" href="class_InferenceEngine_Core.html#doxid-class-inference-engine-1-1-core-1ac716dda382aefd09264b60ea40def3ef"><span class="std std-ref">ReadNetwork</span></a><span></span><span class="p">(</span><span class="s">&quot;sample.xml&quot;</span><span class="p">);</span>
<span class="k">auto</span> <span class="n">function</span> <span class="o">=</span> <span class="n">network</span><span class="p">.</span><a class="reference internal" href="class_InferenceEngine_CNNNetwork.html#doxid-class-inference-engine-1-1-c-n-n-network-1a7246c6936dfc1ebfa2c776e97972f539"><span class="std std-ref">getFunction</span></a><span></span><span class="p">();</span>

<span class="c1">// This example demonstrates how to perform default affinity initialization and then</span>
<span class="c1">// correct affinity manually for some layers</span>
<span class="k">const</span> <span class="n">std</span><span class="o">::</span><span class="n">string</span> <span class="n">device</span> <span class="o">=</span> <span class="s">&quot;HETERO:FPGA,CPU&quot;</span><span class="p">;</span>

<span class="c1">// QueryNetworkResult object contains map layer -&gt; device</span>
<a class="reference internal" href="struct_InferenceEngine_QueryNetworkResult.html#doxid-struct-inference-engine-1-1-query-network-result"><span class="std std-ref">InferenceEngine::QueryNetworkResult</span></a><span></span> <span class="n">res</span> <span class="o">=</span> <span class="n">core</span><span class="p">.</span><a class="reference internal" href="class_InferenceEngine_Core.html#doxid-class-inference-engine-1-1-core-1a0852259214fd9faf2b46bb9720ec825a"><span class="std std-ref">QueryNetwork</span></a><span></span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="p">{</span> <span class="p">});</span>

<span class="c1">// update default affinities</span>
<span class="n">res</span><span class="p">.</span><a class="reference internal" href="struct_InferenceEngine_QueryNetworkResult.html#doxid-struct-inference-engine-1-1-query-network-result-1aff431e5d7451f364dee1c1c54ca78333"><span class="std std-ref">supportedLayersMap</span></a><span></span><span class="p">[</span><span class="s">&quot;layerName&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s">&quot;CPU&quot;</span><span class="p">;</span>

<span class="c1">// set affinities to network</span>
<span class="k">for</span> <span class="p">(</span><span class="k">auto</span><span class="o">&amp;&amp;</span> <span class="nl">node</span> <span class="p">:</span> <span class="n">function</span><span class="o">-&gt;</span><span class="n">get_ops</span><span class="p">())</span> <span class="p">{</span>
    <span class="k">auto</span><span class="o">&amp;</span> <span class="n">affinity</span> <span class="o">=</span> <span class="n">res</span><span class="p">.</span><a class="reference internal" href="struct_InferenceEngine_QueryNetworkResult.html#doxid-struct-inference-engine-1-1-query-network-result-1aff431e5d7451f364dee1c1c54ca78333"><span class="std std-ref">supportedLayersMap</span></a><span></span><span class="p">[</span><span class="n">node</span><span class="o">-&gt;</span><span class="n">get_friendly_name</span><span class="p">()];</span>
    <span class="c1">// Store affinity mapping using node runtime information</span>
    <span class="n">node</span><span class="o">-&gt;</span><span class="n">get_rt_info</span><span class="p">()[</span><span class="s">&quot;affinity&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">std</span><span class="o">::</span><span class="n">make_shared</span><span class="o">&lt;</span><span class="n">ngraph</span><span class="o">::</span><span class="n">VariantWrapper</span><span class="o">&lt;</span><span class="n">std</span><span class="o">::</span><span class="n">string</span><span class="o">&gt;&gt;</span><span class="p">(</span><span class="n">affinity</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// load network with affinities set before</span>
<span class="k">auto</span> <span class="n">executable_network</span> <span class="o">=</span> <span class="n">core</span><span class="p">.</span><a class="reference internal" href="class_InferenceEngine_Core.html#doxid-class-inference-engine-1-1-core-1a7ac4bd8bc351fae833aaa0db84fab738"><span class="std std-ref">LoadNetwork</span></a><span></span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">device</span><span class="p">);</span></pre>
<p>If you rely on the default affinity distribution, you can avoid calling <code class="docutils literal notranslate"><a class="reference internal" href="class_InferenceEngine_Core.html#doxid-class-inference-engine-1-1-core-1a0852259214fd9faf2b46bb9720ec825a"><span class="std std-ref"><span class="pre">InferenceEngine::Core::QueryNetwork</span></span></a></code> and just call <code class="docutils literal notranslate"><a class="reference internal" href="class_InferenceEngine_Core.html#doxid-class-inference-engine-1-1-core-1a7ac4bd8bc351fae833aaa0db84fab738"><span class="std std-ref"><span class="pre">InferenceEngine::Core::LoadNetwork</span></span></a></code> instead:</p>
<pre class="highlight literal-block"><a class="reference internal" href="class_InferenceEngine_Core.html#doxid-class-inference-engine-1-1-core"><span class="std std-ref">InferenceEngine::Core</span></a><span></span> <span class="n">core</span><span class="p">;</span>
<span class="k">auto</span> <span class="n">network</span> <span class="o">=</span> <span class="n">core</span><span class="p">.</span><a class="reference internal" href="class_InferenceEngine_Core.html#doxid-class-inference-engine-1-1-core-1ac716dda382aefd09264b60ea40def3ef"><span class="std std-ref">ReadNetwork</span></a><span></span><span class="p">(</span><span class="s">&quot;sample.xml&quot;</span><span class="p">);</span>
<span class="k">auto</span> <span class="n">executable_network</span> <span class="o">=</span> <span class="n">core</span><span class="p">.</span><a class="reference internal" href="class_InferenceEngine_Core.html#doxid-class-inference-engine-1-1-core-1a7ac4bd8bc351fae833aaa0db84fab738"><span class="std std-ref">LoadNetwork</span></a><span></span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="s">&quot;HETERO:FPGA,CPU&quot;</span><span class="p">);</span></pre>
<p><strong>NOTE</strong> : <code class="docutils literal notranslate"><a class="reference internal" href="class_InferenceEngine_Core.html#doxid-class-inference-engine-1-1-core-1a0852259214fd9faf2b46bb9720ec825a"><span class="std std-ref"><span class="pre">InferenceEngine::Core::QueryNetwork</span></span></a></code> does not depend on affinities set by a user, but queries for layer support based on device capabilities.</p>
</div>
<div class="section" id="details-of-splitting-network-and-execution">
<h2>Details of Splitting Network and Execution<a class="headerlink" href="#details-of-splitting-network-and-execution" title="Permalink to this headline">¶</a></h2>
<p>During loading of the network to heterogeneous plugin, network is divided to separate parts and loaded to dedicated plugins. Intermediate blobs between these sub graphs are allocated automatically in the most efficient way.</p>
</div>
<div class="section" id="execution-precision">
<h2>Execution Precision<a class="headerlink" href="#execution-precision" title="Permalink to this headline">¶</a></h2>
<p>Precision for inference in heterogeneous plugin is defined by</p>
<ul class="simple">
<li><p>Precision of IR.</p></li>
<li><p>Ability of final plugins to execute in precision defined in IR</p></li>
</ul>
<p>Examples:</p>
<ul class="simple">
<li><p>If you want to execute GPU with CPU fallback with FP16 on GPU, you need to use only FP16 IR.</p></li>
<li><p>If you want to execute on FPGA with CPU fallback, you can use any precision for IR. The execution on FPGA is defined by bitstream, the execution on CPU happens in FP32.</p></li>
</ul>
<p>Samples can be used with the following command:</p>
<pre class="highlight literal-block"><span></span><span class="p">.</span><span class="o">/</span><span class="n">object_detection_sample_ssd</span> <span class="o">-</span><span class="n">m</span>  <span class="o">&lt;</span><span class="n">path_to_model</span><span class="o">&gt;/</span><span class="n">ModelSSD</span><span class="p">.</span><span class="n">xml</span> <span class="o">-</span><span class="n">i</span> <span class="o">&lt;</span><span class="n">path_to_pictures</span><span class="o">&gt;/</span><span class="n">picture</span><span class="p">.</span><span class="n">jpg</span> <span class="o">-</span><span class="n">d</span> <span class="nl">HETERO</span><span class="p">:</span><span class="n">FPGA</span><span class="p">,</span><span class="n">CPU</span></pre>
<p>where:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">HETERO</span></code> stands for heterogeneous plugin</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">FPGA,CPU</span></code> points to fallback policy with priority on FPGA and fallback to CPU</p></li>
</ul>
<p>You can point more than two devices: <code class="docutils literal notranslate"><span class="pre">-d</span> <span class="pre">HETERO:FPGA,GPU,CPU</span></code></p>
</div>
<div class="section" id="analyzing-heterogeneous-execution">
<h2>Analyzing Heterogeneous Execution<a class="headerlink" href="#analyzing-heterogeneous-execution" title="Permalink to this headline">¶</a></h2>
<p>After enabling of <code class="docutils literal notranslate"><span class="pre">KEY_HETERO_DUMP_GRAPH_DOT</span></code> config key, you can dump GraphViz* <code class="docutils literal notranslate"><span class="pre">.dot</span></code> files with annotations of devices per layer.</p>
<p>Heterogeneous plugin can generate two files:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">hetero_affinity_&lt;network</span> <span class="pre">name&gt;.dot</span></code> - annotation of affinities per layer. This file is written to the disk only if default fallback policy was executed</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">hetero_subgraphs_&lt;network</span> <span class="pre">name&gt;.dot</span></code> - annotation of affinities per graph. This file is written to the disk during execution of <code class="docutils literal notranslate"><span class="pre">ICNNNetwork::LoadNetwork()</span></code> for heterogeneous plugin</p></li>
</ul>
<pre class="highlight literal-block"><span></span><span class="k">using</span> <span class="k">namespace</span> <a class="reference internal" href="namespace_InferenceEngine_PluginConfigParams.html#doxid-namespace-inference-engine-1-1-plugin-config-params"><span class="std std-ref">InferenceEngine::PluginConfigParams</span></a><span></span><span class="p">;</span>
<span class="k">using</span> <span class="k">namespace</span> <a class="reference internal" href="namespace_InferenceEngine_HeteroConfigParams.html#doxid-namespace-inference-engine-1-1-hetero-config-params"><span class="std std-ref">InferenceEngine::HeteroConfigParams</span></a><span></span><span class="p">;</span>

<span class="c1">// ...</span>
<a class="reference internal" href="class_InferenceEngine_Core.html#doxid-class-inference-engine-1-1-core"><span class="std std-ref">InferenceEngine::Core</span></a><span></span> <span class="n">core</span><span class="p">;</span>
<span class="n">core</span><span class="p">.</span><a class="reference internal" href="class_InferenceEngine_Core.html#doxid-class-inference-engine-1-1-core-1a34aa9ac6fb237b634d5bf08b288e88d4"><span class="std std-ref">SetConfig</span></a><span></span><span class="p">({</span> <span class="p">{</span> <span class="n">KEY_HETERO_DUMP_GRAPH_DOT</span><span class="p">,</span> <a class="reference internal" href="namespace_InferenceEngine_PluginConfigParams.html#doxid-namespace-inference-engine-1-1-plugin-config-params-1a42d48631fa3332ded8c776513e897bf3"><span class="std std-ref">YES</span></a><span></span> <span class="p">}</span> <span class="p">},</span> <span class="s">&quot;HETERO&quot;</span><span class="p">);</span></pre>
<p>You can use GraphViz* utility or converters to <code class="docutils literal notranslate"><span class="pre">.png</span></code> formats. On Ubuntu* operating system, you can use the following utilities:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">sudo</span> <span class="pre">apt-get</span> <span class="pre">install</span> <span class="pre">xdot</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">xdot</span> <span class="pre">hetero_subgraphs.dot</span></code></p></li>
</ul>
<p>You can use performance data (in samples, it is an option <code class="docutils literal notranslate"><span class="pre">-pc</span></code>) to get performance data on each subgraph.</p>
<p>Here is an example of the output: for Googlenet v1 running on FPGA with fallback to CPU:</p>
<pre class="highlight literal-block"><span></span><span class="nl">subgraph1</span><span class="p">:</span> <span class="mf">1.</span> <span class="n">input</span> <span class="n">preprocessing</span> <span class="p">(</span><span class="n">mean</span> <span class="n">data</span><span class="o">/</span><span class="n">FPGA</span><span class="p">)</span><span class="o">:</span><span class="n">EXECUTED</span>       <span class="nl">layerType</span><span class="p">:</span>                    <span class="nl">realTime</span><span class="p">:</span> <span class="mi">129</span>        <span class="nl">cpu</span><span class="p">:</span> <span class="mi">129</span>            <span class="nl">execType</span><span class="p">:</span>
<span class="nl">subgraph1</span><span class="p">:</span> <span class="mf">2.</span> <span class="n">input</span> <span class="n">transfer</span> <span class="n">to</span> <span class="nl">DDR</span><span class="p">:</span><span class="n">EXECUTED</span>       <span class="nl">layerType</span><span class="p">:</span>                    <span class="nl">realTime</span><span class="p">:</span> <span class="mi">201</span>        <span class="nl">cpu</span><span class="p">:</span> <span class="mi">0</span>              <span class="nl">execType</span><span class="p">:</span>
<span class="nl">subgraph1</span><span class="p">:</span> <span class="mf">3.</span> <span class="n">FPGA</span> <span class="n">execute</span> <span class="nl">time</span><span class="p">:</span><span class="n">EXECUTED</span>       <span class="nl">layerType</span><span class="p">:</span>                    <span class="nl">realTime</span><span class="p">:</span> <span class="mi">3808</span>       <span class="nl">cpu</span><span class="p">:</span> <span class="mi">0</span>              <span class="nl">execType</span><span class="p">:</span>
<span class="nl">subgraph1</span><span class="p">:</span> <span class="mf">4.</span> <span class="n">output</span> <span class="n">transfer</span> <a class="reference internal" href="namespace_ngraph_element.html#doxid-namespacengraph-1-1element-1a242815728c496bad0a8194762f63cb2a"><span class="std std-ref">from</span></a><span></span> <span class="nl">DDR</span><span class="p">:</span><span class="n">EXECUTED</span>       <span class="nl">layerType</span><span class="p">:</span>                    <span class="nl">realTime</span><span class="p">:</span> <span class="mi">55</span>         <span class="nl">cpu</span><span class="p">:</span> <span class="mi">0</span>              <span class="nl">execType</span><span class="p">:</span>
<span class="nl">subgraph1</span><span class="p">:</span> <span class="mf">5.</span> <span class="n">FPGA</span> <span class="n">output</span> <span class="nl">postprocessing</span><span class="p">:</span><span class="n">EXECUTED</span>       <span class="nl">layerType</span><span class="p">:</span>                    <span class="nl">realTime</span><span class="p">:</span> <span class="mi">7</span>          <span class="nl">cpu</span><span class="p">:</span> <span class="mi">7</span>              <span class="nl">execType</span><span class="p">:</span>
<span class="nl">subgraph1</span><span class="p">:</span> <span class="mf">6.</span> <span class="n">copy</span> <span class="n">to</span> <span class="n">IE</span> <span class="nl">blob</span><span class="p">:</span><span class="n">EXECUTED</span>       <span class="nl">layerType</span><span class="p">:</span>                    <span class="nl">realTime</span><span class="p">:</span> <span class="mi">2</span>          <span class="nl">cpu</span><span class="p">:</span> <span class="mi">2</span>              <span class="nl">execType</span><span class="p">:</span>
<span class="nl">subgraph2</span><span class="p">:</span> <span class="nl">out_prob</span><span class="p">:</span>          <span class="n">NOT_RUN</span>        <span class="nl">layerType</span><span class="p">:</span> <span class="n">Output</span>             <span class="nl">realTime</span><span class="p">:</span> <span class="mi">0</span>          <span class="nl">cpu</span><span class="p">:</span> <span class="mi">0</span>              <span class="nl">execType</span><span class="p">:</span> <span class="n">unknown</span>
<span class="nl">subgraph2</span><span class="p">:</span> <span class="nl">prob</span><span class="p">:</span>              <span class="n">EXECUTED</span>       <span class="nl">layerType</span><span class="p">:</span> <span class="n">SoftMax</span>            <span class="nl">realTime</span><span class="p">:</span> <span class="mi">10</span>         <span class="nl">cpu</span><span class="p">:</span> <span class="mi">10</span>             <span class="nl">execType</span><span class="p">:</span> <span class="n">ref</span>
<span class="n">Total</span> <span class="nl">time</span><span class="p">:</span> <span class="mi">4212</span>     <span class="n">microseconds</span></pre>
</div>
<div class="section" id="see-also">
<h2>See Also<a class="headerlink" href="#see-also" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p><a class="reference internal" href="openvino_docs_IE_DG_supported_plugins_Supported_Devices.html#doxid-openvino-docs-i-e-d-g-supported-plugins-supported-devices"><span class="std std-ref">Supported Devices</span></a></p></li>
</ul>
</div>
</div>


          </div>
      
      
          <div class='prev-next-bottom'>
            

          </div>
      
    </main>


      </div>
    </div>
  
  <script src="_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  <footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="copyright">
    &copy; Copyright 2021, Intel.<br/>
</p>
    </div>
    
    <div class="footer-item">
      <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 4.1.1.<br/>
</p>
    </div>
    
  </div>
</footer>
  </body>
</html>